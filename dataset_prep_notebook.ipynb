{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:25.215183200Z",
     "start_time": "2023-11-26T09:07:25.193240Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_max_length = 512\n",
    "project = \"alpaca-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "eos_token = '</s>'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:26.369446600Z",
     "start_time": "2023-11-26T09:07:26.359438Z"
    }
   },
   "id": "89d14aaade474cfd"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "dataset = pd.read_json('./data/alpaca_gpt4_data.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:27.159328400Z",
     "start_time": "2023-11-26T09:07:26.983323300Z"
    }
   },
   "id": "b89e884daac87710"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def gen_dataset_splits(ds, perc: [], verbose:False):\n",
    "    ds_len = len(ds)\n",
    "    train_len = int(ds_len * perc[0])\n",
    "    eval_len = int(ds_len * perc[1])\n",
    "    test_len = ds_len - train_len - eval_len\n",
    "    if verbose:\n",
    "        print(f\"train size: {train_len}, validation size:{eval_len}, test size:{test_len} - total size: {ds_len}\")\n",
    "    splits = np.concatenate([\n",
    "        np.zeros(train_len),\n",
    "        np.ones(eval_len),\n",
    "        np.full(test_len, 2)\n",
    "    ])\n",
    "    np.random.shuffle(splits)\n",
    "    return splits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:27.620278100Z",
     "start_time": "2023-11-26T09:07:27.611771900Z"
    }
   },
   "id": "e18ff0bba1292ec3"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 46801, validation size:520, test size:4681 - total size: 52002\n"
     ]
    }
   ],
   "source": [
    "dataset['split'] = gen_dataset_splits(dataset, [.9, .01], verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:28.075061400Z",
     "start_time": "2023-11-26T09:07:28.049683800Z"
    }
   },
   "id": "7afea6e6d7a2bdb"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def alpaca_prompt(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)\n",
    "\n",
    "\n",
    "def alpaca_prompt_input(row):\n",
    "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)\n",
    "\n",
    "\n",
    "def gen_prompt(row):\n",
    "    return (alpaca_prompt(row) if row['input'] == \"\" else alpaca_prompt_input(row)) + row['output'] + eos_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:28.592429100Z",
     "start_time": "2023-11-26T09:07:28.576418200Z"
    }
   },
   "id": "b218f4d19049bd80"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "dataset['prompt'] = dataset.apply(lambda x: gen_prompt(x), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:29.777608500Z",
     "start_time": "2023-11-26T09:07:29.401832800Z"
    }
   },
   "id": "bb1879f50437f85b"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, model_max_length=model_max_length)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:34.134592300Z",
     "start_time": "2023-11-26T09:07:33.360836400Z"
    }
   },
   "id": "c17ef4af85e5cf0e"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# split dataset\n",
    "def get_split(ds, split_id=0):\n",
    "    res = ds[ds['split'] == split_id]\n",
    "    res = res.drop('split', axis=1)\n",
    "    return res\n",
    "\n",
    "\n",
    "train_dataset = get_split(dataset)\n",
    "eval_dataset = get_split(dataset, 1)\n",
    "test_dataset = get_split(dataset, 2)\n",
    "\n",
    "# extract prompts\n",
    "train_prompts = train_dataset['prompt'].to_list()\n",
    "eval_prompts = eval_dataset['prompt'].to_list()\n",
    "test_prompts = test_dataset['prompt'].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:36.018142700Z",
     "start_time": "2023-11-26T09:07:35.946691500Z"
    }
   },
   "id": "70febee7a8474158"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize(prompts, tokenizer):\n",
    "    return tokenizer(prompts, truncation=True)['input_ids']\n",
    "\n",
    "\n",
    "tokenized_train_dataset = tokenize(train_prompts, tokenizer)\n",
    "tokenized_eval_dataset = tokenize(eval_prompts, tokenizer)\n",
    "tokenized_test_dataset = tokenize(test_prompts, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:41.323183800Z",
     "start_time": "2023-11-26T09:07:36.608228500Z"
    }
   },
   "id": "38a7984e29f01884"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# packing\n",
    "def pack(tokens, max_model_size):\n",
    "    packed_tokens = []\n",
    "    i = 0\n",
    "    pack = []\n",
    "    while i < len(tokens):\n",
    "        cur_len = len(pack)\n",
    "        if cur_len + len(tokens[i]) <= max_model_size:\n",
    "            pack.extend(tokens[i])\n",
    "        else:\n",
    "            packed_tokens.append(pack)\n",
    "            pack = tokens[i]\n",
    "        i += 1\n",
    "    if len(pack) > 0:\n",
    "        packed_tokens.append(pack)\n",
    "    return packed_tokens\n",
    "\n",
    "packed_train_data = pack(tokenized_train_dataset, model_max_length)\n",
    "packed_eval_data = pack(tokenized_eval_dataset, model_max_length)\n",
    "packed_test_data = pack(tokenized_test_dataset, model_max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:43.928471200Z",
     "start_time": "2023-11-26T09:07:43.881623900Z"
    }
   },
   "id": "b7c7540a284268b5"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# padding\n",
    "def pad(tokens, max_model_size, pad_token_id=2):\n",
    "    padded_tokens = []\n",
    "    for i in tokens:\n",
    "        cur_len = len(i)\n",
    "        if cur_len >= max_model_size:\n",
    "            padded_tokens.append(i)\n",
    "            continue\n",
    "        needed_padding = max_model_size - cur_len\n",
    "        pad = np.full(needed_padding, pad_token_id)\n",
    "        i.extend(pad)\n",
    "        padded_tokens.append(i)\n",
    "    return padded_tokens\n",
    "\n",
    "packed_padded_train_data = pad(packed_train_data, model_max_length, tokenizer.eos_token_id)\n",
    "packed_padded_eval_data = pad(packed_eval_data, model_max_length, tokenizer.eos_token_id)\n",
    "packed_padded_test_data = pad(packed_test_data, model_max_length, tokenizer.eos_token_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:07:45.674015100Z",
     "start_time": "2023-11-26T09:07:45.379522800Z"
    }
   },
   "id": "41101f87fe3fe5e1"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/25276 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12d9b280c853494a92d546684c974564"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/292 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "413e74135c634cc79a7a94f58a2be1ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/2532 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f86633b86f9e4da5bb06935569c9d0b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save to disk\n",
    "tds = Dataset.from_dict({'input_ids': packed_padded_train_data, 'labels': packed_padded_train_data})\n",
    "eds = Dataset.from_dict({'input_ids': packed_padded_eval_data, 'labels': packed_padded_eval_data})\n",
    "teds = Dataset.from_dict({'input_ids': packed_padded_test_data, 'labels': packed_padded_test_data})\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': tds,\n",
    "    \"eval\": eds,\n",
    "    'test': teds\n",
    "})\n",
    "\n",
    "ds.save_to_disk(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T09:08:41.084173800Z",
     "start_time": "2023-11-26T09:08:38.809658300Z"
    }
   },
   "id": "8d02598b9f0fd9b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71ab7a1b8b570bb2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
